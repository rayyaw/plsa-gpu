/**
 * @file stage4_cpu_postprocessing.cpp
 * @author RileyTech
 * @brief Keep only the most important information from the stage 3 output, in preparation for stage 5 (information display)
 * @date 2023-04-15
 * 
 * @copyright Copyright (c) 2023. Licensed under CC-BY SA.
 * 
 */

// C headers
#include <stdio.h>
#include <stdlib.h>

// C++ headers
#include <fstream>
#include <iostream>
#include <map>
#include <utility>
#include <vector>

// Local headers
#include "stage3/emStep.h"

using std::cerr;
using std::cout;
using std::endl;
using std::getline;
using std::ifstream;
using std::map;
using std::ofstream;
using std::pair;
using std::string;
using std::vector;

// Load EM data from file. Generated by ChatGPT.
EMstep loadFromFile() {

    FILE* doc_f = fopen("model/document_coverage.bin", "rb");
    FILE* topic_f = fopen("model/topic_models.bin", "rb");

    if (!doc_f || !topic_f) {
        cerr << "Unable to open counts file. Please check your data." << endl;
        exit(-1);
    }

    size_t num_topics, num_documents, vocab_size;

    // Read the sizes from the topic file
    fread(&num_topics, sizeof(size_t), 1, topic_f);
    fread(&num_documents, sizeof(size_t), 1, topic_f);
    fread(&vocab_size, sizeof(size_t), 1, topic_f);

    EMstep em = EMstep(num_topics, num_documents, vocab_size);

    // Read the arrays from the files
    fread(em.document_coverage, sizeof(double), num_topics * num_documents, doc_f);
    fread(em.topic_models, sizeof(double), num_topics * vocab_size, topic_f);

    // Close the files
    fclose(doc_f);
    fclose(topic_f);

    return em;
}

// Return index-to-word mappings. Generated by ChatGPT.
map<size_t, string> indexToWord() {
    ifstream file("model/word_encodings.txt");
    string line;
    map<size_t, string> lineMap;

    size_t lineNumber = 0;
    while (getline(file, line)) {
        lineMap[lineNumber++] = line;
    }

    return lineMap;
}

// Get the k largest values within an array, and their index. Sorted by descending probability.
vector<pair<double, size_t>> getLargestValues(const double *arr, size_t arr_size, int num_outputs) {
    vector<pair<double, size_t>> outputs = vector<pair<double, size_t>>(num_outputs);

    // Naive approach of iterating through arr num_outputs times
    // NOTE: This is very slow
    for (int i = 0; i < num_outputs; i++) {
        double current = 0;
        size_t current_idx = 0;

        for (size_t j = 0; j < arr_size; j++) {
            // Handle the edge case of being the first element
            if (arr[j] > current && (i == 0 || arr[j] < outputs[i-1].first)) {
                current = arr[j];
                current_idx = j;
            }
        }

        outputs[i] = pair<double, size_t>(current, current_idx);
    }

    return outputs;
}

// argv[1] = k = an integer
// We only keep the k most likely words per topic
// We should also save as words rather than indices to speed up stage 5 lookups
int main(int argc, char *argv[]) {
    if (argc != 2) {
        cerr << argv[0] << " " << "[top_words_per_topic (int)]" << endl;
    }

    EMstep data = loadFromFile();
    map<size_t, string> word_conversion_map = indexToWord();

    // No convenient way to get size_t instead... we have to make do
    int words_per_topic = atoi(argv[1]);

    vector<vector<pair<double, size_t>>> most_common_word_indices = vector<vector<pair<double, size_t>>>(data.num_topics);

    for (size_t i = 0; i < data.num_topics; i++) {
        most_common_word_indices[i] = getLargestValues(data.topic_models + (i * data.vocab_size), data.vocab_size, words_per_topic);
    }

    // Convert words from index (numerical) to string representation
    vector<vector<pair<double, string>>> most_common_words = vector<vector<pair<double, string>>>(data.num_topics);
    for (size_t i = 0; i < data.num_topics; i++) {
        most_common_words[i] = vector<pair<double, string>>(words_per_topic);

        for (int j = 0; j < words_per_topic; j++) {
            most_common_words[i][j] = pair<double, string>(most_common_word_indices[i][j].first, 
                                                           word_conversion_map[most_common_word_indices[i][j].second]);
        }
    }

    // Save these values to a file
    ofstream stage4_output("model/topic_summary.txt");

    stage4_output << data.num_topics << endl;
    stage4_output << data.num_documents << endl;
    stage4_output << words_per_topic << endl;

    // Save in topic-major order
    for (size_t i = 0; i < data.num_topics; i++) {
        for (int j = 0; j < words_per_topic; j++) {
            stage4_output << most_common_words[i][j].first << " " << most_common_words[i][j].second << endl;
        }
    }

    stage4_output.close();

    cout << "Stage 4 completed." << endl;
}